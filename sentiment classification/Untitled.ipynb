{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e95e833-30d0-421b-acef-b4d3d547cc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lutfi\\miniconda3\\envs\\negation-sa\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from torch import clamp\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class TokenSimilarity:\n",
    "\n",
    "    def load_pretrained(self, from_pretrained:str=\"indobenchmark/indobert-base-p1\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(from_pretrained)\n",
    "        self.model = AutoModel.from_pretrained(from_pretrained)\n",
    "        \n",
    "    def __cleaning(self, text:str):\n",
    "        # clear punctuations\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "        # clear multiple spaces\n",
    "        text = re.sub(r'/s+', ' ', text).strip()\n",
    "\n",
    "        return text\n",
    "        \n",
    "    def __process(self, first_token:str, second_token:str):\n",
    "        inputs = self.tokenizer([first_token, second_token],\n",
    "                                max_length=self.max_length,\n",
    "                                truncation=self.truncation,\n",
    "                                padding=self.padding,\n",
    "                                return_tensors='pt')\n",
    "\n",
    "        attention = inputs.attention_mask\n",
    "\n",
    "        outputs = self.model(**inputs)\n",
    "\n",
    "        # get the weights from the last layer as embeddings\n",
    "        embeddings = outputs[0] # when used in older transformers version\n",
    "        # embeddings = outputs.last_hidden_state # when used in newer one\n",
    "\n",
    "        # add more dimension then expand tensor\n",
    "        # to match embeddings shape by duplicating its values by rows\n",
    "        mask = attention.unsqueeze(-1).expand(embeddings.shape).float()\n",
    "\n",
    "        masked_embeddings = embeddings * mask\n",
    "        \n",
    "        # MEAN POOLING FOR 2ND DIMENSION\n",
    "        # first, get sums by 2nd dimension\n",
    "        # second, get counts of 2nd dimension\n",
    "        # third, calculate the mean, i.e. sums/counts\n",
    "        summed = masked_embeddings.sum(1)\n",
    "        counts = clamp(mask.sum(1), min=1e-9)\n",
    "        mean_pooled = summed/counts\n",
    "\n",
    "        # return mean pooling as numpy array\n",
    "        return mean_pooled.detach().numpy()\n",
    "        \n",
    "    def predict(self, first_token:str, second_token:str,\n",
    "                return_as_embeddings:bool=False, max_length:int=16,\n",
    "                truncation:bool=True, padding:str=\"max_length\"):\n",
    "        self.max_length = max_length\n",
    "        self.truncation = truncation\n",
    "        self.padding = padding\n",
    "\n",
    "        first_token = self.__cleaning(first_token)\n",
    "        second_token = self.__cleaning(second_token)\n",
    "\n",
    "        mean_pooled_arr = self.__process(first_token, second_token)\n",
    "        if return_as_embeddings:\n",
    "            return mean_pooled_arr\n",
    "\n",
    "        # calculate similarity\n",
    "        similarity = cosine_similarity([mean_pooled_arr[0]], [mean_pooled_arr[1]])\n",
    "\n",
    "        return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a7464f-de74-4da2-9da8-16fb494f7a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TokenSimilarity()\n",
    "model.load_pretrained('indobenchmark/indobert-base-p2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57a8e112-3e23-4b96-b5bf-06bd739d119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"membeli\"\n",
    "str2 = \"menjauh\"\n",
    "str3 = \"meminjam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf5f162-17b9-405a-8950-0740dd9e8a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.86526513]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(str1, str3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5451f97-6834-4630-bbab-bcf61f327977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000002]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(str2, str3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6daf112-01ea-4b31-bf89-3fd3c5a63606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(text1, text2):\n",
    "    words = text1.split()\n",
    "    results={}\n",
    "    for word in words:\n",
    "        results[word] = model.predict(word, text2)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34748be3-b82f-476a-b3d4-fe5c29305de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"dijaga reputasinya oleh pemilik produk\"\n",
    "text2 = \"Beli 2 kotak isi total 20 buah pie terdapat 5 buah pie yang sudah jamuran. Padahal paket langsung dibuka sesaat setelah diantar kurir dan expire date juga masih 1 bulan lebih. Coba cek ulasan, banyak pembeli juga mengalami kendala pie berjamur. Jelek sekali kontrol kualitas pie susu ini. Kasian reputasi toko ini ikutan rusak gara-gara produk yang . Maaf ya kaka penjual, ini ulasan jujur. Mungkin bisa disampaikan kepada produsen produk agar memperbaiki kontrol kualitas produknya.\"\n",
    "get_similarity(text1, text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9313c668-351a-4193-b39b-641a1ee63b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "x =model.get_mean_pooled_arr(text1, text2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d491bd3-15a9-4044-9fc7-c0b153785ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ac686e-4629-468a-8363-155cb2cf6286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c0aa49-42c3-4dfd-8269-068ce32c9c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 0, 0, 0]]\n",
    "b = [[1, 0, 0, 0]]\n",
    "cosine_similarity(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cf27e8-9ba2-4625-9b95-293b1d7518ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa8de3a-b2f0-45c8-b619-fedf81c46c40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
